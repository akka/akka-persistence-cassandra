
# This configures the default settings for all Cassandra Journal plugin
# instances in the system. If you are using just one configuration for
# all persistent actors then you should point your akka.persistence.journal.plugin
# setting to this section.
#
# Otherwise you need to create differently named sections containing
# only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-journal = ${cassandra-journal}
#   my-cassandra-journal {
#     <settings...>
#   }
cassandra-journal {

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Comma-separated list of contact points in the cluster.
  # Host:Port pairs are also supported. In that case the port parameter will be ignored.
  contact-points = ["127.0.0.1"]

  # Port of contact points in the cluster.
  # Will be ignored if the contact point list is defined by host:port pairs.
  port = 9042
  
  # The implementation of akka.persistence.cassandra.SessionProvider
  # is used for creating the Cassandra Session. By default the 
  # the ConfigSessionProvider is building the Cluster from configuration properties
  # but it is possible to replace the implementation of the SessionProvider
  # to reuse another session or override the Cluster builder with other
  # settings.
  # For example, it is possible to lookup the contact points of the Cassandra cluster
  # asynchronously instead of giving them in the configuration in a subclass of
  # ConfigSessionProvider and overriding the lookupContactPoints method.
  # It may optionally have a constructor with an ActorSystem and Config parameter.
  # The config parameter is this config section of the plugin.
  session-provider = akka.persistence.cassandra.ConfigSessionProvider
  
  # The identifier that will be passed as parameter to the
  # ConfigSessionProvider.lookupContactPoints method. 
  cluster-id = ""

  # Name of the keyspace to be created/used by the journal
  keyspace = "akka"

  # Parameter indicating whether the journal keyspace should be auto created
  keyspace-autocreate = true

  # The number of retries when a write request returns a TimeoutException or an UnavailableException.
  write-retries = 3

  # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
  # Number of retries before giving up
  delete-retries = 3
  
  # Number of retries before giving up connecting to the cluster
  connect-retries = 3
  
  # Delay between connection retries
  connect-retry-delay = 1s

  # Cassandra driver connection pool settings
  # Documented at https://datastax.github.io/java-driver/features/pooling/
  connection-pool {

    # Create new connection threshold local
    new-connection-threshold-local = 800

    # Create new connection threshold remote
    new-connection-threshold-remote = 200

    # Connections per host core local
    connections-per-host-core-local = 1

    # Connections per host max local
    connections-per-host-max-local = 4

    # Connections per host core remote
    connections-per-host-core-remote = 1

    # Connections per host max remote
    connections-per-host-max-remote = 4

    # Max requests per connection local
    max-requests-per-connection-local = 32768

    # Max requests per connection remote
    max-requests-per-connection-remote = 2000

    # Sets the timeout when trying to acquire a connection from a host's pool
    pool-timeout-millis = 0
  }

  # Name of the table to be created/used by the journal.
  # If the table doesn't exist it is automatically created.
  table = "messages"

  # Compaction strategy for the journal table.
  # Please refer to the tests for example configurations.
  # Refer to http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html 
  # for more information regarding the properties.
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for storing metadata.
  # If the table doesn't exist it is automatically created.
  metadata-table = "metadata"

  # Name of the table to be created/used for journal config.
  # If the table doesn't exist it is automatically created.
  config-table = "config"
  
  # Set this to on to only use Cassandra 2.x compatible features,
  # i.e. if you are using a Cassandra 2.x server.
  # To run tests with Cassandra 2.x server you have to do the following:
  # - start Cassandra 2.x server on default port 9042, with empty data directory
  # - change CassandraLauncher.randomPort to 9042
  # - change CassandraLauncher.start to do nothing
  # - set this cassandra-2x-compat = on
  # - note that you must delete all data between each test run
  cassandra-2x-compat = off

  # Possibility to disable the eventsByTag query and creation of
  # the materialized view. This will automatically be off when
  # cassandra-2x-compat=on 
  enable-events-by-tag-query = on
  
  # Name of the materialized view for eventsByTag query
  events-by-tag-view = "eventsbytag"
  
  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []
  
  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to. 
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = ""
  
  # To connect to the Cassandra hosts with credentials.
  # Authentication is disabled if username is not configured.
  authentication.username = ""
  authentication.password = ""
  
  # SSL can be configured with the following properties.
  # SSL is disabled if the truststore is not configured.
  # For detailed instructions, please refer to the DataStax Cassandra chapter about 
  # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
  # Path to the JKS Truststore file 
  ssl.truststore.path = ""
  # Password to unlock the JKS Truststore
  ssl.truststore.password = ""
  # Path to the JKS Keystore file (optional config, only needed for client authentication)
  ssl.keystore.path = ""
  # Password to unlock JKS Truststore and access the private key (both must use the same password)
  ssl.keystore.password = "" 

  # Write consistency level
  # The default read and write consistency levels ensure that persistent actors can read their own writes.
  # During normal operation, persistent actors only write to the journal, reads occur only during recovery.
  write-consistency = "QUORUM"

  # Read consistency level
  read-consistency = "QUORUM"

  # Maximum number of messages that will be batched when using `persistAsync`. 
  # Also used as the max batch size for deletes.
  max-message-batch-size = 100

  # Target number of entries per partition (= columns per row).
  # Must not be changed after table creation (currently not checked).
  # This is "target" as AtomicWrites that span partition boundaries will result in bigger partitions to ensure atomicity.
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001

  # Maximum size of result set during replay
  max-result-size-replay = 50001

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-journal.default-dispatcher"

  # The query journal to use when recoverying
  query-plugin = "cassandra-query-journal"

  # Default dispatcher for plugin actor and task.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }

  # The time to wait before cassandra will remove the thombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000
  
  # When using more than one tag per event you have to configure know 
  # tags in this section to give each tag an identifier. When using 
  # only one tag per event the identifier is 1, automatically.
  # tagname = tagid
  # where tagid must be 1, 2, or 3. Max 3 tags per event is supported.
  # For example:
  #   BlogPosts = 1
  #   Announcement = 2
  #   Authors = 1
  # With those tag identifiers you can use BlogPosts and Announcement for a single event,
  # but you cannot combine BlogPosts and Authors, since they have the same tag identifier.  
  tags {
  }
  
  # Minimum time between publishing messages to DistributedPubSub to announce events for a specific tag have
  # been written. These announcements cause any ongoing getEventsByTag to immediately re-poll, rather than
  # wait. In order enable this feature, make the following settings:
  #  
  #    - enable clustering for your actor system
  #    - cassandra-journal.pubsub-minimum-interval = 1s              (send real-time announcements at most every sec)
  #    - cassandra-query-journal.eventual-consistency-delay = 0s     (so it immediately tries to show changes)
  #
  # Setting pubsub-minimum-interval to "off" will disable the journal sending these announcements. 
  pubsub-minimum-interval = off
  
  # Set the protocol version explicitly, should only be used for compatibility testing.
  # Supported values: 3, 4
  protocol-version = ""
}

# This configures the default settings for all Cassandra Snapshot plugin
# instances in the system. If you are using just one configuration for
# all persistent actors then you should point your akka.persistence.snapshot-store.plugin
# setting to this section.
#
# Otherwise you need to create differently named sections containing
# only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-snapshot-store = ${cassandra-snapshot-store}
#   my-cassandra-snapshot-store {
#     <settings...>
#   }
cassandra-snapshot-store {

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Comma-separated list of contact points in the cluster.
  # Host:Port pairs are also supported. In that case the port parameter will be ignored.
  contact-points = ["127.0.0.1"]

  # Port of contact points in the cluster.
  # Will be ignored if the contact point list is defined by host:port pairs.
  port = 9042
  
  # The implementation of akka.persistence.cassandra.SessionProvider
  # is used for creating the Cassandra Session. By default the 
  # the ConfigSessionProvider is building the Cluster from configuration properties
  # but it is possible to replace the implementation of the SessionProvider
  # to reuse another session or override the Cluster builder with other
  # settings.
  # For example, it is possible to lookup the contact points of the Cassandra cluster
  # asynchronously instead of giving them in the configuration in a subclass of
  # ConfigSessionProvider and overriding the lookupContactPoints method.
  # It may optionally have a constructor with an ActorSystem and Config parameter.
  # The config parameter is this config section of the plugin.
  session-provider = akka.persistence.cassandra.ConfigSessionProvider
  
  # The identifier that will be passed as parameter to the
  # ConfigSessionProvider.lookupContactPoints method. 
  cluster-id = ""

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "akka_snapshot"

  # Parameter indicating whether the snapshot keyspace should be auto created
  keyspace-autocreate = true

  # Number of retries before giving up connecting to the cluster
  connect-retries = 3
  
  # Delay between connection retries
  connect-retry-delay = 1s

  # Cassandra driver connection pool settings
  # Documented at https://datastax.github.io/java-driver/features/pooling/
  # and http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/PoolingOptions.html
  connection-pool {

    # Create new connection threshold local
    new-connection-threshold-local = 50

    # Create new connection threshold remote
    new-connection-threshold-remote = 50

    # Connections per host core local
    connections-per-host-core-local = 1

    # Connections per host max local
    connections-per-host-max-local = 4

    # Connections per host core remote
    connections-per-host-core-remote = 1

    # Connections per host max remote
    connections-per-host-max-remote = 4

    # Max requests per connection local
    max-requests-per-connection-local = 32768

    # Max requests per connection remote
    max-requests-per-connection-remote = 2000

    # Sets the timeout when trying to acquire a connection from a host's pool
    pool-timeout-millis = 0
  }

  # Name of the table to be created/used by the snapshot store.
  # If the table doesn't exist it is automatically created.
  table = "snapshots"

  # Compaction strategy for the snapshot table
  # Please refer to the tests for example configurations.
  # Refer to http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html 
  # for more information regarding the properties.
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for journal config.
  # If the table doesn't exist it is automatically created.
  config-table = "config"

  # Name of the table to be created/used for storing metadata.
  # If the table doesn't exist it is automatically created.
  metadata-table = "metadata"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []
  
  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to. 
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = ""
  
  # To connect to the Cassandra hosts with credentials.
  # Authentication is disabled if username is not configured.
  authentication.username = ""
  authentication.password = ""
  
  # SSL can be configured with the following properties.
  # SSL is disabled if the truststore is not configured.
  # For detailed instructions, please refer to the DataStax Cassandra chapter about 
  # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
  # Path to the JKS Truststore file 
  ssl.truststore.path = ""
  # Password to unlock the JKS Truststore
  ssl.truststore.password = ""
  # Path to the JKS Keystore file (optional config, only needed for client authentication)
  ssl.keystore.path = ""
  # Password to unlock JKS Truststore and access the private key (both must use the same password)
  ssl.keystore.password = ""

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum number of snapshot metadata to load per recursion (when trying to
  # find a snapshot that matches specified selection criteria). Only increase
  # this value when selection criteria frequently select snapshots that are
  # much older than the most recent snapshot i.e. if there are much more than
  # 10 snapshots between the most recent one and selected one. This setting is
  # only for increasing load efficiency of snapshots.
  max-metadata-result-size = 10

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor and task.
  plugin-dispatcher = "cassandra-snapshot-store.default-dispatcher"

  # Default dispatcher for plugin actor.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
  
  # Set the protocol version explicitly, should only be used for compatibility testing.
  # Supported values: 3, 4
  protocol-version = ""
}

# This configures the default settings for all CassandraReadJournal plugin
# instances in the system.
#
# If you use multiple plugin instances you need to create differently named 
# sections containing only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-query-journal = ${cassandra-query-journal}
#   my-cassandra-query-journal {
#     <settings...>
#   }
cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"
  
  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"
  
  # New events are retrieved (polled) with this interval.
  refresh-interval = 3s
  
  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = 500
  
  # The fetch size of the Cassandra select statement
  # Value less or equal to 0 means max-result-size will be used
  # http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/Statement.html
  max-result-size-query = 250
  
  # Read consistency level
  read-consistency = "QUORUM"
  
  # Configure this to the day (yyyyMMdd) when the system was first started.
  # When offset 0L is used it will look for events from this day and forward.
  first-time-bucket = "20151120"

  # The returned event stream is ordered by the offset (timestamp), which corresponds
  # to the same order as the write journal stored the events, with inaccuracy due to clock skew
  # between different nodes. The same stream elements (in same order) are returned for multiple
  # executions of the query on a best effort basis. The query is using a Cassandra Materialized
  # View for the query and that is eventually consistent, so different queries may see different
  # events for the latest events, but eventually the result will be ordered by timestamp
  # (Cassandra timeuuid column). To compensate for the the eventual consistency the query is
  # delayed to not read the latest events, the duration of this delay is defined by this 
  # configuration property.
  # However, this is only best effort and in case of network partitions
  # or other things that may delay the updates of the Materialized View the events may be
  # delivered in different order (not strictly by their timestamp).  
  eventual-consistency-delay = 10s
  
  # If you use the same tag for all events for a `persistenceId` it is possible to get
  # a more strict delivery order than otherwise. This can be useful when all events of
  # a PersistentActor class (all events of all instances of that PersistentActor class)
  # are tagged with the same tag. Then the events for each `persistenceId` can be delivered
  # strictly by sequence number. If a sequence number is missing the query is delayed up 
  # to the configured `delayed-event-timeout` and if the expected event is still not 
  # found the stream is completed with failure. This means that there must not be any 
  # holes in the sequence numbers for a given tag, i.e. all events must be tagged
  # with the same tag. Set this property to for example 30s to enable this feature.
  # It is disabled by default.
  delayed-event-timeout = 0s
  
  # Dispatcher for the plugin actors.
  plugin-dispatcher = "cassandra-query-journal.default-dispatcher"
  
  # Default dispatcher for plugin actor and tasks.
  default-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
      parallelism-min = 2
      parallelism-max = 8
    }
  }
}
