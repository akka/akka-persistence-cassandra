
# This configures the default settings for all Cassandra Journal plugin
# instances in the system. If you are using just one configuration for
# all persistent actors then you should point your akka.persistence.journal.plugin
# setting to this section.
#
# Otherwise you need to create differently named sections containing
# only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-journal = ${cassandra-journal}
#   my-cassandra-journal {
#     <settings...>
#   }
cassandra-journal {

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  # Comma-separated list of contact points in the Cassandra cluster.
  # Host:Port pairs are also supported. In that case the port parameter will be ignored.
  contact-points = ["127.0.0.1"]

  # Port of contact points in the Cassandra cluster.
  # Will be ignored if the contact point list is defined by host:port pairs.
  port = 9042

  # The implementation of akka.persistence.cassandra.SessionProvider
  # is used for creating the Cassandra Session. By default the 
  # the ConfigSessionProvider is building the Cluster from configuration properties
  # but it is possible to replace the implementation of the SessionProvider
  # to reuse another session or override the Cluster builder with other
  # settings.
  # For example, it is possible to lookup the contact points of the Cassandra cluster
  # asynchronously instead of giving them in the configuration in a subclass of
  # ConfigSessionProvider and overriding the lookupContactPoints method.
  # It may optionally have a constructor with an ActorSystem and Config parameter.
  # The config parameter is this config section of the plugin.
  session-provider = akka.persistence.cassandra.ConfigSessionProvider

  # The identifier that will be passed as parameter to the
  # ConfigSessionProvider.lookupContactPoints method. 
  cluster-id = ""

  # Name of the keyspace to be created/used by the journal
  keyspace = "akka"

  # Parameter indicating whether the journal keyspace should be auto created.
  # Not all Cassandra settings are configurable when using autocreate and for
  # full control of the keyspace and table definitions you should create them 
  # manually (with a script).
  keyspace-autocreate = true

  # Parameter indicating whether the journal tables should be auto created
  # Not all Cassandra settings are configurable when using autocreate and for
  # full control of the keyspace and table definitions you should create them 
  # manually (with a script).
  tables-autocreate = true

  # The number of retries when a write request returns a TimeoutException or an UnavailableException.
  write-retries = 3

  # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
  # Number of retries before giving up
  delete-retries = 3

  # The number of retries when a read query fails.
  read-retries = 3

  # Set this to a positive integer to enable speculative executions.
  # The value defines the number of speculative executions that will be
  # performed with the delay defined by 'speculative-executions-delay'.
  # See http://docs.datastax.com/en/developer/java-driver/3.1/manual/speculative_execution/
  # If you enable this you should also enable cassandra-query-journal.speculative-executions
  # which is used for the relay query.
  speculative-executions = 0

  # See 'speculative-executions' 
  speculative-executions-delay = 1s

  # Number of retries before giving up connecting for the initial connection to the Cassandra cluster
  connect-retries = 3

  # Delay between connection retries, for the initial connection to the Cassandra cluster
  connect-retry-delay = 1s

  # Max delay of the ExponentialReconnectionPolicy that is used when reconnecting
  # to the Cassandra cluster
  reconnect-max-delay = 30s

  # Enable debug logging of queries as described in 
  # https://docs.datastax.com/en/developer/java-driver/3.1/manual/logging/#logging-query-latencies 
  log-queries = off

  # Akka-persistence allows multiple pending deletes for the same persistence id however this plugin only executes one
  # at a time per persistence id (deletes for different persistenceIds can happen concurrently).
  #
  # If multiple deletes for the same persistence id are received then they are queued.
  #
  # If the queue is full any subsequent deletes are failed immediately without attempting them in Cassandra.
  #
  # Deleting should be used with snapshots for efficiency for recovery thus deleting should be infrequent
  max-concurrent-deletes = 10

  # Cassandra driver connection pool settings
  # Documented at http://docs.datastax.com/en/developer/java-driver/latest/manual/pooling/
  connection-pool {

    # Create new connection threshold local
    new-connection-threshold-local = 800

    # Create new connection threshold remote
    new-connection-threshold-remote = 200

    # Connections per host core local
    connections-per-host-core-local = 1

    # Connections per host max local
    connections-per-host-max-local = 4

    # Connections per host core remote
    connections-per-host-core-remote = 1

    # Connections per host max remote
    connections-per-host-max-remote = 4

    # Max requests per connection local
    max-requests-per-connection-local = 32768

    # Max requests per connection remote
    max-requests-per-connection-remote = 2000

    # Sets the timeout when trying to acquire a connection from a host's pool
    pool-timeout-millis = 0

    # Sets the maximum number of requests that get enqueued if no connection is available.
    max-queue-size = 256
  }

  # Name of the table to be created/used by the journal.
  # If the table doesn't exist it is automatically created.
  table = "messages"

  # Compaction strategy for the journal table.
  # Please refer to the tests for example configurations.
  # Refer to http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html 
  # for more information regarding the properties.
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for storing metadata.
  # If the table doesn't exist it is automatically created.
  metadata-table = "metadata"

  # Name of the table to be created/used for journal config.
  # If the table doesn't exist it is automatically created.
  config-table = "config"

  # TODO remove this and just query cassandra to see what version it is
  # Set this to on to only use Cassandra 2.x compatible features,
  # i.e. if you are using a Cassandra 2.x server.
  # To run tests with Cassandra 2.x server you have to do the following:
  # - start Cassandra 2.x server on default port 9042, with empty data directory
  # - change CassandraLauncher.randomPort to 9042
  # - change CassandraLauncher.start to do nothing
  # - set this cassandra-2x-compat = on
  # - note that you must delete all data between each test run
  cassandra-2x-compat = off

  events-by-tag {
    # Enable/disable events by tag. If eventsByTag queries aren't required then this should be set to
    # false to avoid the overhead of maintaining the tag_views table.
    enabled = true

    # Tagged events are written to a separate Cassandra table in unlogged batches
    # Max size of these batches
    max-message-batch-size = 200

    # Max time to buffer events for before writing.
    # Larger valeues will increase cassandra write efficiency but increase the delay before
    # seeing events in EventsByTag queries.
    # Setting this to 0 means that tag writes will get written immediately but will still be asynchronous
    # with respect to the PersistentActor's persist call. However, this will be very bad for throughput.
    flush-interval = 250ms

    # Update the tag_scanning table with this interval. Shouldn't be done too often to
    # avoid unecessary load. The tag_scanning table keeps track of a starting point for tag
    # scanning during recovery of persistent actor.
    scanning-flush-interval = 30s

    table = "tag_views"
    gc-grace-seconds = 864000
    compaction-strategy {
      class = "SizeTieredCompactionStrategy"
      # If setting a time-to-live then consider using TimeWindowCompactionStratery
      # See [here](http://thelastpickle.com/blog/2016/12/08/TWCS-part1.html) for guideance.
      # It is reccommended not to have more than 50 buckets so this needs to be based on your
      # time-to-live e.g. if you set the TTL to 50 hours and the compaction window to 1 hour
      # there will be 50 buckets.
      # class = "TimeWindowCompactionStrategy"
      # compaction_window_unit = "HOURS"
      # compaction_window_size = 1
    }

    # How long events are kept for in the tag_views table
    # By default the events are kept for ever. Uncomment and set to an appropriate
    # duration for your use case. See the compaction-strategy.class if you set this
    #time-to-live = 2d

    # WARNING: Can not be changed after data has been written
    #
    # Unless you have a significant (million+) of events for a single tag
    # do not change this to Minute. Each tag in the tag-views table has a partition
    # per tag per bucket
    # Valid options: Day, Hour, Minute
    bucket-size = "Hour"
  }

  # meta columns were added in version 0.55. If you don't alter existing messages table and still
  # use `tables-autocreate=on` you have to set this property to off.
  # When trying to create the materialized view with the meta columns before corresponding columns
  # have been added the messages table an exception "Undefined column name meta_ser_id" is raised,
  # because Cassandra validates the "CREATE MATERIALIZED VIEW IF NOT EXISTS"
  # even though the view already exists and will not be created. To work around that issue you can disable the
  # meta data columns in the materialized view by setting this property to off.
  meta-in-events-by-tag-view = on

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to. 
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = ""

  # Number of hosts from non-local datacenter to use as a fall-back policy.
  # Works only when local-datacenter is set
  used-hosts-per-remote-dc = 0

  # To connect to the Cassandra hosts with credentials.
  # Authentication is disabled if username is not configured.
  authentication.username = ""
  authentication.password = ""

  # SSL can be configured with the following properties.
  # SSL is disabled if the truststore is not configured.
  # For detailed instructions, please refer to the DataStax Cassandra chapter about 
  # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
  # Path to the JKS Truststore file 
  ssl.truststore.path = ""
  # Password to unlock the JKS Truststore
  ssl.truststore.password = ""
  # Path to the JKS Keystore file (optional config, only needed for client authentication)
  ssl.keystore.path = ""
  # Password to unlock JKS Truststore and access the private key (both must use the same password)
  ssl.keystore.password = ""

  # Write consistency level
  # The default read and write consistency levels ensure that persistent actors can read their own writes.
  # During normal operation, persistent actors only write to the journal, reads occur only during recovery.
  write-consistency = "QUORUM"

  # Read consistency level
  read-consistency = "QUORUM"

  # Maximum number of messages that will be batched when using `persistAsync`. 
  # Also used as the max batch size for deletes.
  max-message-batch-size = 100

  # Target number of entries per partition (= columns per row).
  # Must not be changed after table creation (currently not checked).
  # This is "target" as AtomicWrites that span partition boundaries will result in bigger partitions to ensure atomicity.
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 250

  # Maximum size of result set during replay
  max-result-size-replay = 250

  # The query journal to use when recovering
  query-plugin = "cassandra-query-journal"

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-plugin-default-dispatcher"

  # The time to wait before cassandra will remove the tombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on 
  # http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000

  # Enable DistributedPubSub to announce events for a specific tag have
  # been written. These announcements cause any ongoing getEventsByTag to immediately re-poll, rather than
  # wait. In order enable this feature, make the following settings:
  #  
  #    - enable clustering for your actor system
  #    - cassandra-journal.pubsub-notification=on              (send real-time announcements at most every sec)
  #
  # Setting pubsub-notification to "off" will disable the journal sending these announcements.
  pubsub-notification = off

  # Set the protocol version explicitly, should only be used for compatibility testing.
  # Supported values: 3, 4
  protocol-version = ""

  # Options to configure low-level socket options for the connections to Cassandra hosts
  # See: https://datastax.github.io/java-driver/manual/socket_options
  socket {

    # how long the driver waits to establish a new connection to a Cassandra node before giving up
    connection-timeout-millis = 5000

    # the per-host read timeout in milliseconds. Should be higher than the timeout settings used on the Cassandra side
    read-timeout-millis = 12000

    # a hint to the size of the underlying buffers for outgoing network I/O. Set to zero to
    # use the default from the underlying Netty transport (Java NIO or native epoll)
    send-buffer-size = 0

    # a hint to the size of the underlying buffers for incoming network I/O. Set to zero to
    # use the default from the underlying Netty transport (Java NIO or native epoll)
    receive-buffer-size = 0
  }


}

# This configures the default settings for all Cassandra Snapshot plugin
# instances in the system. If you are using just one configuration for
# all persistent actors then you should point your akka.persistence.snapshot-store.plugin
# setting to this section.
#
# Otherwise you need to create differently named sections containing
# only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-snapshot-store = ${cassandra-snapshot-store}
#   my-cassandra-snapshot-store {
#     <settings...>
#   }
cassandra-snapshot-store {

  # FQCN of the cassandra snapshot store plugin
  class = "akka.persistence.cassandra.snapshot.CassandraSnapshotStore"

  # Comma-separated list of contact points in the Cassandra cluster.
  # Host:Port pairs are also supported. In that case the port parameter will be ignored.
  contact-points = ["127.0.0.1"]

  # Port of contact points in the Cassandra cluster.
  # Will be ignored if the contact point list is defined by host:port pairs.
  port = 9042

  # The implementation of akka.persistence.cassandra.SessionProvider
  # is used for creating the Cassandra Session. By default the
  # the ConfigSessionProvider is building the Cluster from configuration properties
  # but it is possible to replace the implementation of the SessionProvider
  # to reuse another session or override the Cluster builder with other
  # settings.
  # For example, it is possible to lookup the contact points of the Cassandra cluster
  # asynchronously instead of giving them in the configuration in a subclass of
  # ConfigSessionProvider and overriding the lookupContactPoints method.
  # It may optionally have a constructor with an ActorSystem and Config parameter.
  # The config parameter is this config section of the plugin.
  session-provider = akka.persistence.cassandra.ConfigSessionProvider

  # The identifier that will be passed as parameter to the
  # ConfigSessionProvider.lookupContactPoints method.
  cluster-id = ""

  # Name of the keyspace to be created/used by the snapshot store
  keyspace = "akka_snapshot"

  # Parameter indicating whether the snapshot keyspace should be auto created
  # Not all Cassandra settings are configurable when using autocreate and for
  # full control of the keyspace and table definitions you should create them 
  # manually (with a script).
  keyspace-autocreate = true

  # Parameter indicating whether the snapshot tables should be auto created
  # Not all Cassandra settings are configurable when using autocreate and for
  # full control of the keyspace and table definitions you should create them 
  # manually (with a script).
  tables-autocreate = true

  # The number of retries when a write request returns a TimeoutException or an UnavailableException.
  write-retries = 3

  # Number of retries before giving up
  delete-retries = 3

  # The number of retries when a read query fails.
  read-retries = 3

  # Set this to a positive integer to enable speculative executions.
  # The value defines the number of speculative executions that will be
  # performed with the delay defined by 'speculative-executions-delay'.
  # See http://docs.datastax.com/en/developer/java-driver/3.1/manual/speculative_execution/
  speculative-executions = 0

  # See 'speculative-executions' 
  speculative-executions-delay = 1s

  # Number of retries before giving up connecting for the initial connection to the Cassandra cluster
  connect-retries = 3

  # Delay between connection retries, for the initial connection to the Cassandra cluster
  connect-retry-delay = 1s

  # Max delay of the ExponentialReconnectionPolicy that is used when reconnecting
  # to the Cassandra cluster
  reconnect-max-delay = 30s

  # Enable debug logging of queries as described in 
  # https://docs.datastax.com/en/developer/java-driver/3.1/manual/logging/#logging-query-latencies 
  log-queries = off

  # Cassandra driver connection pool settings
  # Documented at http://docs.datastax.com/en/developer/java-driver/latest/manual/pooling/
  # and http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/PoolingOptions.html
  connection-pool {

    # Create new connection threshold local
    new-connection-threshold-local = 50

    # Create new connection threshold remote
    new-connection-threshold-remote = 50

    # Connections per host core local
    connections-per-host-core-local = 1

    # Connections per host max local
    connections-per-host-max-local = 4

    # Connections per host core remote
    connections-per-host-core-remote = 1

    # Connections per host max remote
    connections-per-host-max-remote = 4

    # Max requests per connection local
    max-requests-per-connection-local = 32768

    # Max requests per connection remote
    max-requests-per-connection-remote = 2000

    # Sets the timeout when trying to acquire a connection from a host's pool
    pool-timeout-millis = 0

    # Sets the maximum number of requests that get enqueued if no connection is available.
    max-queue-size = 256
  }

  # Name of the table to be created/used by the snapshot store.
  # If the table doesn't exist it is automatically created.
  table = "snapshots"

  # Compaction strategy for the snapshot table
  # Please refer to the tests for example configurations.
  # Refer to http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html
  # for more information regarding the properties.
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for journal config.
  # If the table doesn't exist it is automatically created.
  config-table = "config"

  # Name of the table to be created/used for storing metadata.
  # If the table doesn't exist it is automatically created.
  metadata-table = "metadata"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to.
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = ""

  # Number of hosts from non-local datacenter to use as a fall-back policy.
  # Works only when local-datacenter is set
  used-hosts-per-remote-dc = 0

  # To connect to the Cassandra hosts with credentials.
  # Authentication is disabled if username is not configured.
  authentication.username = ""
  authentication.password = ""

  # SSL can be configured with the following properties.
  # SSL is disabled if the truststore is not configured.
  # For detailed instructions, please refer to the DataStax Cassandra chapter about
  # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
  # Path to the JKS Truststore file
  ssl.truststore.path = ""
  # Password to unlock the JKS Truststore
  ssl.truststore.password = ""
  # Path to the JKS Keystore file (optional config, only needed for client authentication)
  ssl.keystore.path = ""
  # Password to unlock JKS Truststore and access the private key (both must use the same password)
  ssl.keystore.password = ""

  # Write consistency level
  write-consistency = "ONE"

  # Read consistency level
  read-consistency = "ONE"

  # Maximum size of result set
  max-result-size = 50001

  # Dispatcher for the plugin actor and task.
  plugin-dispatcher = "cassandra-plugin-default-dispatcher"

  # Set the protocol version explicitly, should only be used for compatibility testing.
  # Supported values: 3, 4
  protocol-version = ""

  # The time to wait before cassandra will remove the tombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on 
  # http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000

  # Options to configure low-level socket options for the connections to Cassandra hosts
  # See: http://docs.datastax.com/en/developer/java-driver/latest/manual/socket_options
  socket {

    # how long the driver waits to establish a new connection to a Cassandra node before giving up
    connection-timeout-millis = 5000

    # the per-host read timeout in milliseconds. Should be higher than the timeout settings used on the Cassandra side
    read-timeout-millis = 12000

    # a hint to the size of the underlying buffers for outgoing network I/O. Set to zero to
    # use the default from the underlying Netty transport (Java NIO or native epoll)
    send-buffer-size = 0

    # a hint to the size of the underlying buffers for incoming network I/O. Set to zero to
    # use the default from the underlying Netty transport (Java NIO or native epoll)
    receive-buffer-size = 0
  }

  # Number load attempts when recovering from the latest snapshot fails
  # yet older snapshot files are available. Each recovery attempt will try
  # to recover using an older than previously failed-on snapshot file 
  # (if any are present). If all attempts fail the recovery will fail and
  # the persistent actor will be stopped.
  max-load-attempts = 3
}

# This configures the default settings for all CassandraReadJournal plugin
# instances in the system.
#
# If you use multiple plugin instances you need to create differently named 
# sections containing only those settings that shall be different from the defaults
# configured here, importing the defaults like so:
#
#   my-cassandra-query-journal = ${cassandra-query-journal}
#   my-cassandra-query-journal {
#     <settings...>
#   }
cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"

  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = 3s

  # Sequence numbers for a persistenceId is assumed to be monotonically increasing
  # without gaps. That is used for detecting missing events.
  # In early versions of the journal that might not be true and therefore
  # this can be relaxed by setting this property to off.
  gap-free-sequence-numbers = on

  # When using LQ writing in one DC and querying in another, the events for an entity may
  # appear in the querying DC out of order, when that happens, try for this amount of
  # time to find the in-order sequence number before failing the stream
  events-by-persistence-id-gap-timeout = 10s

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = 500

  # The fetch size of the Cassandra select statement
  # Value less or equal to 0 means max-result-size will be used
  # http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/Statement.html
  max-result-size-query = 250

  # When the available rows without fetching in the ResultSet reach this threshold
  # more will be fetched asynchronously. 
  # Value should be between 0.0 and 1.0.
  # E.g. threshold of 0.1 and fetch size of 250 will trigger new fetch when 
  # 25 rows are available. 
  fetch-more-threshold = 0.2

  # Read consistency level
  read-consistency = "QUORUM"

  # The number of retries when a read query fails.
  read-retries = 3

  # Set this to a positive integer to enable speculative executions.
  # The value defines the number of speculative executions that will be
  # performed with the delay defined by 'speculative-executions-delay'.
  # See http://docs.datastax.com/en/developer/java-driver/3.1/manual/speculative_execution/
  speculative-executions = 0

  # See 'speculative-executions' 
  speculative-executions-delay = 1s

  # Configure this to the first bucket eventByTag queries will start from in the format
  # yyyyMMddTHH:mm yyyyMMdd is also supported if using Day as a bucket size
  # Will be rounded down to the start of whatever time bucket it falls into
  # When NoOffset is used it will look for events from this day and forward.
  first-time-bucket = "20151120T00:00"

  events-by-tag {
    # How long to look for delayed events
    # This works by adding an additional (internal) sequence number to each tag / persistence id
    # event stream so that the read side can detect missing events. When a gap is detected no new events
    # are emitted from the stream until either the missing events are found or the timeout is reached
    # If the event is not found it is checked every `refresh-interval` so do not set this lower than that
    # if you want at least one retry
    # When looking for missing events only the current time bucket and the previous bucket are checked meaning that if
    # clocks are out of sync, or cassandra replication is out by more than your bucket size (minute, hour or day)
    # then the missing events won't be found
    gap-timeout = 10s

    # When a new persistenceId is found in an eventsByTag query that wasn't found in the initial offset scanning
    # period as it didn't have any events in the current time bucket, this is how long the stage will delay events
    # looking for any smaller tag pid sequence nrs. 0s means that the found event is assumed to be the first.
    # The edge case is if events for a not previously seen persistenceId come out of order then if this is set to
    # 0s the newer event will be delivered and when the older event is found the stream will fail as events have
    # to be delivered in order.
    new-persistence-id-scan-timeout = 100ms

    # For offset queries that start in the current time bucket a period of scanning
    # takes place before deliverying events to look for the lowest sequence number
    # for each persistenceId. Any value above 0 will result in at least one scan from
    # the offset to (offset + period). Larger values will result in a longer period of time
    # before the stream starts emitting events.
    offset-scanning-period = 200ms
  }

  # Deserialization of events is perfomed in an Akka streams mapAsync operator and this is the
  # parallelism for that. Increasing to means that deserialization is pipelined, which can
  # be an advantage for machines with many CPU cores but otherwise it might be slower because
  # of higher CPU saturation and more competing tasks when there are many concurrent queries or
  # replays.
  deserialization-parallelism = 1

  # Dispatcher for the plugin actors.
  plugin-dispatcher = "cassandra-plugin-default-dispatcher"
}

# Default dispatcher for plugin actor and tasks.
cassandra-plugin-default-dispatcher {
  type = Dispatcher
  executor = "fork-join-executor"
  fork-join-executor {
    parallelism-min = 6
    parallelism-factor = 1
    parallelism-max = 6
  }
}

